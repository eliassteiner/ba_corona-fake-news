{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01_Data_Agregation.ipynb","provenance":[],"authorship_tag":"ABX9TyMHm4h2Eul+T9QecYfgiSgv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"UIYv0p9uDxZq"},"outputs":[],"source":["# This is a Python 3 environment\n","\n","# Base level imports for data science work\n","import numpy as np \n","import pandas as pd\n","import re,string,unicodedata\n","import os\n","from os import path\n","from json import decoder\n","import glob, os, json\n","\n","# Visualization Libs\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n","\n","# NLP Libs\n","import nltk\n","from sklearn.preprocessing import LabelBinarizer\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","from wordcloud import WordCloud,STOPWORDS\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize,sent_tokenize\n","from bs4 import BeautifulSoup\n","from keras.preprocessing import text, sequence\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.linear_model import PassiveAggressiveClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import SVC\n","\n","# Additional Libs\n","from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n","from sklearn.model_selection import train_test_split\n","from string import punctuation\n","from nltk import pos_tag\n","from nltk.corpus import wordnet\n","\n","# Deep Learning Libs\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense,Embedding,LSTM,Dropout\n","from keras.callbacks import ReduceLROnPlateau\n","import tensorflow as tf"]},{"cell_type":"code","source":["# Mounting Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"wcDi2fnND531"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd /content/drive/MyDrive/BA/0.4/Sources/"],"metadata":{"id":"Gyv6cZsuD8w6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Importieren der .json Daten \n","watson = pd.read_json(\"watson.txt\")\n","blick = pd.read_json(\"blick.json\")\n","klatv = pd.read_json(\"klatv.json\")\n","fangcovid = pd.read_csv(\"full.csv\")\n","twitter = pd.read_csv(\"Twitter_Data.csv\")\n","\n","# Anpassen und setzen der Spalten für Watson\n","watson['type'] = 0\n","watson['fake'] = 0"],"metadata":{"id":"bcZfDokpD_QU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Anpassungen für FANG-COVID\n","#df_fangcovid = pd.DataFrame()\n","#fangcovid.label = fangcovid.label.map({ 'fake' : 1, 'real' : 0})\n","#df_fangcovid['fake'] = fangcovid['label']\n","#del fangcovid['label']\n","#df_fangcovid['content'] =  fangcovid['header'] + fangcovid['article']\n","#del fangcovid['article']\n","#del fangcovid['header']\n","#del fangcovid['twitter-history']\n","#df_fangcovid['url'] = fangcovid['url']\n","#df_fangcovid['source'] = fangcovid['source']\n","#del fangcovid\n"],"metadata":{"id":"iXhVo11vEDkC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd Telegram"],"metadata":{"id":"tDyDWUPrEHLS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Importieren der verschiedenen Telegram Chats und sppecihern in eine Variabel\n","telegram = pd.read_json(\"1.json\")\n","telegram = telegram.append(pd.read_json(\"2.json\"))\n","telegram = telegram.append(pd.read_json(\"3.json\"))\n","telegram = telegram.append(pd.read_json(\"4.json\"))\n","telegram = telegram.append(pd.read_json(\"5.json\"))\n","\n","# Umwandeln der Telegram Variabel in ein DF und Anpassen der Spaltennamen\n","df_telegram = pd.DataFrame()\n","df_telegram['content'] =telegram['message']\n","df_telegram['source'] = 'Telegram'\n","df_telegram['type']= 2\n","df_telegram['fake'] = 1"],"metadata":{"id":"GzKmxufmESXa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Removing dublicates\n","watson=watson.drop_duplicates()\n","blick=blick.drop_duplicates()\n","klatv=klatv.drop_duplicates()\n","df_telegram=df_telegram.drop_duplicates()"],"metadata":{"id":"uJGAlkm_EWkM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Finales Dataframe mit den Quellen\n","df = watson\n","df = df.append(blick)\n","df = df.append(klatv)\n","df = df.append(df_telegram)\n","#df = df.append(df_fangcovid)"],"metadata":{"id":"14eVo3sREbxb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del watson,blick,klatv,df_telegram\n","#del df_fangcovid"],"metadata":{"id":"1mbLorRlEd0m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['text'] = df['content']\n","\n","# This will delete all the other columns we do not need for the rest of the work.\n","del df['link'] \n","del df['author']\n","del df['published'] \n","del df['updated']\n","del df['content']\n","del df['type']\n","del df['url']\n","del df['source']"],"metadata":{"id":"qCcqR0EiEhTa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Export DF for reuse\n","#df.sample(10)\n","df.to_csv('df_ba.csv')\n","!cp df_ba.csv \"/content/drive/MyDrive/BA/Project/df_ba.csv\""],"metadata":{"id":"cwMsl2QdElQ7"},"execution_count":null,"outputs":[]}]}